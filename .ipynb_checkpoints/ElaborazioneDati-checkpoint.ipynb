{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRWos7EAz5ne",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import dipendeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 740,
     "status": "ok",
     "timestamp": 1655304178382,
     "user": {
      "displayName": "Carmine Martinelli",
      "userId": "17979448709595778797"
     },
     "user_tz": -120
    },
    "id": "asX5o8d9AMMy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 44414,
     "status": "ok",
     "timestamp": 1655304225101,
     "user": {
      "displayName": "Carmine Martinelli",
      "userId": "17979448709595778797"
     },
     "user_tz": -120
    },
    "id": "7eM0PG6QUg8c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Modifica la precisione nella visualizzazione delle cifre\n",
    "pd.options.display.precision = 10\n",
    "\n",
    "## Importa i dati dal file excel\n",
    "df_DatiSensori = pd.read_excel('Dati_gruppo1.xlsx')\n",
    "\n",
    "# Mostra tutte le colonne\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rinomina le colonne con carattersi speciali e assegna il valore di soglia \n",
    "df_DatiSensori.rename(columns = {'C6H6_ug/m3':'C6H6_ug_m3', 'H2S_ug/m3':'H2S_ug_m3', 'H2SJ_ug/m3':'H2SJ_ug_m3'}, inplace = True)\n",
    "threshold = 24\n",
    "\n",
    "# crea una copia del dataset per lavorarci\n",
    "df_Dati = df_DatiSensori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restituisce la lista con gli indici delle righe con almeno un valore di threshold di zeri consecutivi\n",
    "def find_fail(colonna, df, threshold): \n",
    "    index, dizionario = {} , {}\n",
    "    listaTagli, out  = [], []\n",
    "    df1 =df[[colonna]].copy() \n",
    "    df1[\"Somma\"] = df1.rolling(threshold).sum() \n",
    "    for i in df1.index: \n",
    "        if df1['Somma'][i] == 0: \n",
    "            index[i] = df1['Somma'][i] \n",
    "    indici = list(index.keys()) \n",
    "    for i in range(len(indici)-1): \n",
    "        if (indici[i+1] - indici[i] > 1): \n",
    "            listaTagli.append(i) \n",
    "    listaTagli.append(0) \n",
    "    listaTagli.sort() \n",
    "    for i in range(len(listaTagli)-1): \n",
    "        if i == 0: \n",
    "            dizionario[i] = indici[listaTagli[i]:listaTagli[i+1]+1] \n",
    "        else: \n",
    "            dizionario[i] = indici[listaTagli[i]+1:listaTagli[i+1]+1] \n",
    "    dizionario[len(dizionario.values())] = indici[listaTagli[-1]+1:] \n",
    "    if (len(dizionario[0]) == 0):\n",
    "      return out\n",
    "    else:\n",
    "      for key in dizionario.keys(): \n",
    "          maxIndice= dizionario[key][0] \n",
    "          minIndice = maxIndice - threshold \n",
    "          maxIndice = maxIndice + len(dizionario[key]) - 1 \n",
    "          out = out + list(np.arange(minIndice,maxIndice+1)) \n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo diversi dataframe quanti sono i sensori ed effettuo il controllo sui 24 zeri consecutivi ritenuti fallimento\n",
    "# e infine effettuo il drop degli indici delle righe trovate\n",
    "dfTRS = df_Dati[['TRS_ppb', 'TRS_stato']]\n",
    "dfTRS = dfTRS.drop(find_fail('TRS_ppb', df_Dati, threshold)).reset_index()#TRS_ppb\n",
    "dfVOC = df_Dati[['VOC_ppm', 'VOC_stato']]\n",
    "dfVOC = dfVOC.drop(find_fail('VOC_ppm', df_Dati, threshold)).reset_index() #VOC\n",
    "dfC6H6 = df_Dati[['C6H6_ug_m3', 'C6H6_stato']]\n",
    "dfC6H6 = dfC6H6.drop(find_fail('C6H6_ug_m3', df_Dati, threshold)).reset_index().reset_index() #C6H6_ug/m3\n",
    "dfH2S = df_Dati[['H2S_ug_m3', 'H2S_stato']]\n",
    "dfH2S = dfH2S.drop(find_fail('H2S_ug_m3', df_Dati, threshold)).reset_index() #H2S_ug/m3\n",
    "dfH2SJ = df_Dati[['H2SJ_ug_m3', 'H2SJ_stato']]\n",
    "dfH2SJ = dfH2SJ.drop(find_fail('H2SJ_ug_m3', df_Dati, threshold)).reset_index() #H2SJ_ug/m3\n",
    "dfPIDVOC = df_Dati[['PIDVOC_ppb', 'PIDVOC_stato']]\n",
    "dfPIDVOC = dfPIDVOC.drop(find_fail('PIDVOC_ppb', df_Dati, threshold)).reset_index() #PIDVOC_ppb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152376"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfTRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DatiPuliti = pd.concat([dfTRS[['TRS_ppb', 'TRS_stato']], dfVOC[['VOC_ppm', 'VOC_stato']],\n",
    "                           dfC6H6[['C6H6_ug_m3', 'C6H6_stato']],dfH2S[['H2S_ug_m3', 'H2S_stato']],\n",
    "                           dfH2SJ[['H2SJ_ug_m3', 'H2SJ_stato']],dfPIDVOC[['PIDVOC_ppb', 'PIDVOC_stato']]], axis=1)\n",
    "df_DatiPuliti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimina i valori ND\n",
    "df_DatiPuliti = df_DatiPuliti[~df_Dati.TRS_stato.str.match('ND')]\n",
    "df_DatiPuliti "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimina i valori NaN \n",
    "df_DatiPuliti = df_Dati.dropna().reset_index(drop=True)\n",
    "df_DatiPuliti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Dati\n",
    "# scrive il dataset su disco\n",
    "df_DatiPuliti.to_excel('datiPuliti.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1655304229556,
     "user": {
      "displayName": "Carmine Martinelli",
      "userId": "17979448709595778797"
     },
     "user_tz": -120
    },
    "id": "Jp4Vpjsgz5nl",
    "outputId": "92fbd876-807c-4d8e-d24a-e0d0a2ddcc8e"
   },
   "outputs": [],
   "source": [
    "# query effettuata con un unico comando\n",
    "# df_Benzene = df_DatiSensori.sort_values(by='C6H6_ug/m3', ascending =False)[['postazione', 'Data', 'C6H6_ug/m3']].head(100)\n",
    "\n",
    "# creazione di un dataFrame ordinato in modo discendente per i valori di benzene\n",
    "df_C6H6 = df_DatiPuliti.sort_values(by='C6H6_ug_m3', ascending =False).drop_duplicates(subset=['Data'])\n",
    "# creazione di un dataFrame contenente i 100 maggiori valori di benzene\n",
    "df_C6H6 = df_C6H6[['postazione', 'Data', 'C6H6_ug_m3']]\n",
    "df_C6H6.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5TlwbyEz5nm"
   },
   "outputs": [],
   "source": [
    "# sensore H2S\n",
    "\n",
    "# query effettuata con un unico comando\n",
    "# df_H2S = df_DatiSensori.sort_values(by='H2S_ug/m3', ascending =False)[['postazione', 'Data', 'H2S_ug/m3']].head(100)\n",
    "\n",
    "# creazione di un dataFrame ordinato in modo discendente per i valori di acido solfidrico del sensore H2S\n",
    "df_H2S = df_DatiPuliti.sort_values(by='H2S_ug_m3', ascending =False).drop_duplicates(subset=['Data'])\n",
    "# creazione di un dataFrame contenente i 100 maggiori valori di acido solfidrico del sensore H2SJ\n",
    "df_H2S = df_H2S[['postazione', 'Data', 'H2S_ug_m3']].head(100)\n",
    "df_H2S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42y6B_Svz5nm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sensore H2SJ\n",
    "\n",
    "# query effettuata con un unico comando\n",
    "# df_H2SJ = df_DatiSensori.sort_values(by='H2SJ_ug/m3', ascending =False)[['postazione', 'Data', 'H2SJ_ug/m3']].head(100)\n",
    "\n",
    "# creazione di un dataFrame ordinato in modo discendente per i valori di acido solfidrico del sensore H2SJ\n",
    "df_H2SJ = df_DatiPuliti.sort_values(by='H2SJ_ug_m3', ascending =False).drop_duplicates(subset=['Data'])\n",
    "# creazione di un dataFrame contenente i 100 maggiori valori di acido solfidrico del sensore H2SJ\n",
    "df_H2SJ = df_H2SJ[['postazione', 'Data', 'H2SJ_ug_m3']].head(100)\n",
    "df_H2SJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAzMuBQWz5nn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sensore VOC\n",
    "\n",
    "# query effettuata con un unico comando\n",
    "# df_VOC = df_DatiSensori.sort_values(by='VOC_ppm', ascending =True)[['postazione', 'Data', 'VOC_ppm']].head(100)\n",
    "\n",
    "# creazione di un dataFrame ordinato in modo discendente per i valori del sensore VOC\n",
    "df_VOC = df_DatiPuliti.sort_values(by='VOC_ppm', ascending =True).drop_duplicates(subset=['Data'])\n",
    "# creazione di un dataFrame contenente i 100 più bassi valori del sensore VOC\n",
    "df_VOC = df_VOC[['postazione', 'Data', 'VOC_ppm']].head(100)\n",
    "df_VOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQcNGJiyz5no",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sensore PIDVOC\n",
    "\n",
    "# query effettuata con un unico comando\n",
    "# df_PIDVOC = df_DatiSensori.sort_values(by='PIDVOC_ppb', ascending =True)[['postazione', 'Data', 'PIDVOC_ppb']].head(100)\n",
    "\n",
    "# creazione di un dataFrame ordinato in modo discendente per i valori del sensore PIDVOC\n",
    "df_PIDVOC = df_DatiPuliti.sort_values(by='PIDVOC_ppb', ascending =True).drop_duplicates(subset=['Data'])\n",
    "# creazione di un dataFrame contenente i 100 più bassi valori del sensore PIDVOC\n",
    "df_PIDVOC = df_PIDVOC[['postazione', 'Data', 'PIDVOC_ppb']].head(100)\n",
    "df_PIDVOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H90_aPnbz5np"
   },
   "outputs": [],
   "source": [
    "# Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione che permette di eliminare i valori nulli, calcola la media oraria e restituisce un dataframe ordinato sull'ora\n",
    "def media_oraria(df, compound ):\n",
    "  df1 = df[['postazione', 'Data', compound]].copy()\n",
    "  df1['Data'] = pd.to_datetime(df1['Data'])\n",
    "  df1 = df1[df1[compound].notna()]\n",
    "  indexName = df1[(df1[compound]==0)].index\n",
    "  df1.drop(indexName, inplace = True)\n",
    "  return df1, df1[['Data', compound]].resample(\"H\", label = 'right', on = 'Data').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1655304751704,
     "user": {
      "displayName": "Carmine Martinelli",
      "userId": "17979448709595778797"
     },
     "user_tz": -120
    },
    "id": "6y6LFUlgz5nq"
   },
   "outputs": [],
   "source": [
    "# Creazione dataframe ordinato sulla media oraria\n",
    "df_C6H6, df_C6H6avg = media_oraria(df_DatiPuliti, 'C6H6_ug_m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "wJ4C4Rr7z5nr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C6H6_ug_m3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-23 17:00:00</th>\n",
       "      <td>0.8041666709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 16:00:00</th>\n",
       "      <td>0.7812500025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 18:00:00</th>\n",
       "      <td>0.7666666682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 19:00:00</th>\n",
       "      <td>0.7291666704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 15:00:00</th>\n",
       "      <td>0.7021276634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 21:00:00</th>\n",
       "      <td>0.6666666692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 14:00:00</th>\n",
       "      <td>0.6645833353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28 16:00:00</th>\n",
       "      <td>0.6625000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-24 14:00:00</th>\n",
       "      <td>0.6562500087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-10 14:00:00</th>\n",
       "      <td>0.6527777736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-24 13:00:00</th>\n",
       "      <td>0.6520833460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 20:00:00</th>\n",
       "      <td>0.6479166659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29 18:00:00</th>\n",
       "      <td>0.6458333371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28 15:00:00</th>\n",
       "      <td>0.6395833381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09 17:00:00</th>\n",
       "      <td>0.6333333378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 13:00:00</th>\n",
       "      <td>0.6250000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29 15:00:00</th>\n",
       "      <td>0.6229166705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29 19:00:00</th>\n",
       "      <td>0.6187500060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-23 19:00:00</th>\n",
       "      <td>0.6145833458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-23 18:00:00</th>\n",
       "      <td>0.6145833420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-27 16:00:00</th>\n",
       "      <td>0.6125000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29 16:00:00</th>\n",
       "      <td>0.6125000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09 16:00:00</th>\n",
       "      <td>0.6083333306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-11 19:00:00</th>\n",
       "      <td>0.6000000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-24 12:00:00</th>\n",
       "      <td>0.6000000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-11 18:00:00</th>\n",
       "      <td>0.5979166764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-27 17:00:00</th>\n",
       "      <td>0.5875000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-27 15:00:00</th>\n",
       "      <td>0.5875000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-08 11:00:00</th>\n",
       "      <td>0.5875000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-20 18:00:00</th>\n",
       "      <td>0.5854166740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-27 18:00:00</th>\n",
       "      <td>0.5854166721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28 14:00:00</th>\n",
       "      <td>0.5851063944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29 17:00:00</th>\n",
       "      <td>0.5812500101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 12:00:00</th>\n",
       "      <td>0.5808510711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-08 10:00:00</th>\n",
       "      <td>0.5770833424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-08 14:00:00</th>\n",
       "      <td>0.5770833393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-07 15:00:00</th>\n",
       "      <td>0.5767441933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-08 12:00:00</th>\n",
       "      <td>0.5750000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09 11:00:00</th>\n",
       "      <td>0.5733333468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-08 13:00:00</th>\n",
       "      <td>0.5729166741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09 13:00:00</th>\n",
       "      <td>0.5729166723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29 14:00:00</th>\n",
       "      <td>0.5702127706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-11 20:00:00</th>\n",
       "      <td>0.5666666826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09 20:00:00</th>\n",
       "      <td>0.5659574568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28 12:00:00</th>\n",
       "      <td>0.5630434881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-20 19:00:00</th>\n",
       "      <td>0.5625000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09 12:00:00</th>\n",
       "      <td>0.5625000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28 13:00:00</th>\n",
       "      <td>0.5604166786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-27 14:00:00</th>\n",
       "      <td>0.5604166730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-08 15:00:00</th>\n",
       "      <td>0.5583333398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       C6H6_ug_m3\n",
       "Data                             \n",
       "2021-06-23 17:00:00  0.8041666709\n",
       "2021-06-23 16:00:00  0.7812500025\n",
       "2021-06-23 18:00:00  0.7666666682\n",
       "2021-06-23 19:00:00  0.7291666704\n",
       "2021-06-23 15:00:00  0.7021276634\n",
       "2021-06-23 21:00:00  0.6666666692\n",
       "2021-06-23 14:00:00  0.6645833353\n",
       "2021-06-28 16:00:00  0.6625000052\n",
       "2021-05-24 14:00:00  0.6562500087\n",
       "2021-07-10 14:00:00  0.6527777736\n",
       "2021-05-24 13:00:00  0.6520833460\n",
       "2021-06-23 20:00:00  0.6479166659\n",
       "2021-06-29 18:00:00  0.6458333371\n",
       "2021-06-28 15:00:00  0.6395833381\n",
       "2021-07-09 17:00:00  0.6333333378\n",
       "2021-06-23 13:00:00  0.6250000037\n",
       "2021-06-29 15:00:00  0.6229166705\n",
       "2021-06-29 19:00:00  0.6187500060\n",
       "2021-05-23 19:00:00  0.6145833458\n",
       "2021-05-23 18:00:00  0.6145833420\n",
       "2021-06-27 16:00:00  0.6125000107\n",
       "2021-06-29 16:00:00  0.6125000051\n",
       "2021-07-09 16:00:00  0.6083333306\n",
       "2021-08-11 19:00:00  0.6000000065\n",
       "2021-05-24 12:00:00  0.6000000052\n",
       "2021-08-11 18:00:00  0.5979166764\n",
       "2021-06-27 17:00:00  0.5875000072\n",
       "2021-06-27 15:00:00  0.5875000072\n",
       "2021-07-08 11:00:00  0.5875000053\n",
       "2021-06-20 18:00:00  0.5854166740\n",
       "2021-06-27 18:00:00  0.5854166721\n",
       "2021-06-28 14:00:00  0.5851063944\n",
       "2021-06-29 17:00:00  0.5812500101\n",
       "2021-06-23 12:00:00  0.5808510711\n",
       "2021-07-08 10:00:00  0.5770833424\n",
       "2021-07-08 14:00:00  0.5770833393\n",
       "2021-07-07 15:00:00  0.5767441933\n",
       "2021-07-08 12:00:00  0.5750000055\n",
       "2021-07-09 11:00:00  0.5733333468\n",
       "2021-07-08 13:00:00  0.5729166741\n",
       "2021-07-09 13:00:00  0.5729166723\n",
       "2021-06-29 14:00:00  0.5702127706\n",
       "2021-08-11 20:00:00  0.5666666826\n",
       "2021-07-09 20:00:00  0.5659574568\n",
       "2021-06-28 12:00:00  0.5630434881\n",
       "2021-06-20 19:00:00  0.5625000112\n",
       "2021-07-09 12:00:00  0.5625000112\n",
       "2021-06-28 13:00:00  0.5604166786\n",
       "2021-06-27 14:00:00  0.5604166730\n",
       "2021-07-08 15:00:00  0.5583333398"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stampa le 50 ore con i livelli di benzene più alti\n",
    "df_C6H6Max = df_C6H6avg.sort_values('C6H6_ug_m3', ascending = False).head(50)\n",
    "df_C6H6Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true,
    "id": "29GB_Un3z5nr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C6H6_ug_m3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-19 03:00:00</th>\n",
       "      <td>0.1500000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18 01:00:00</th>\n",
       "      <td>0.1500000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-19 02:00:00</th>\n",
       "      <td>0.1525000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-19 01:00:00</th>\n",
       "      <td>0.1666666692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 05:00:00</th>\n",
       "      <td>0.1666666692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-26 03:00:00</th>\n",
       "      <td>0.1666666702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18 02:00:00</th>\n",
       "      <td>0.1675000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-19 04:00:00</th>\n",
       "      <td>0.1729166697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18 00:00:00</th>\n",
       "      <td>0.1729166699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 02:00:00</th>\n",
       "      <td>0.1729729756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 03:00:00</th>\n",
       "      <td>0.1739130461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 04:00:00</th>\n",
       "      <td>0.1739130461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 01:00:00</th>\n",
       "      <td>0.1750000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-25 01:00:00</th>\n",
       "      <td>0.1750000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-19 00:00:00</th>\n",
       "      <td>0.1750000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-26 04:00:00</th>\n",
       "      <td>0.1750000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-25 05:00:00</th>\n",
       "      <td>0.1800000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-25 04:00:00</th>\n",
       "      <td>0.1804347855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-25 02:00:00</th>\n",
       "      <td>0.1853658568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-25 06:00:00</th>\n",
       "      <td>0.1866666699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-25 03:00:00</th>\n",
       "      <td>0.1869565252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 06:00:00</th>\n",
       "      <td>0.1911111154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-15 08:00:00</th>\n",
       "      <td>0.1916666708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18 03:00:00</th>\n",
       "      <td>0.1916666708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-19 02:00:00</th>\n",
       "      <td>0.1970588289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-22 05:00:00</th>\n",
       "      <td>0.1979166702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 00:00:00</th>\n",
       "      <td>0.1979166710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-20 22:00:00</th>\n",
       "      <td>0.2000000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-19 04:00:00</th>\n",
       "      <td>0.2000000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-18 18:00:00</th>\n",
       "      <td>0.2000000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-18 20:00:00</th>\n",
       "      <td>0.2000000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-18 19:00:00</th>\n",
       "      <td>0.2000000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-19 07:00:00</th>\n",
       "      <td>0.2000000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 23:00:00</th>\n",
       "      <td>0.2000000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-25 00:00:00</th>\n",
       "      <td>0.2020833377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-18 22:00:00</th>\n",
       "      <td>0.2028571484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-19 05:00:00</th>\n",
       "      <td>0.2028571484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-19 06:00:00</th>\n",
       "      <td>0.2028571484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02 02:00:00</th>\n",
       "      <td>0.2051282101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-18 21:00:00</th>\n",
       "      <td>0.2055555615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-18 23:00:00</th>\n",
       "      <td>0.2058823586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-19 09:00:00</th>\n",
       "      <td>0.2058823586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-19 08:00:00</th>\n",
       "      <td>0.2058823586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-15 00:00:00</th>\n",
       "      <td>0.2062500059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-15 09:00:00</th>\n",
       "      <td>0.2063829837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-20 21:00:00</th>\n",
       "      <td>0.2083333383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-31 23:00:00</th>\n",
       "      <td>0.2083333383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-17 07:00:00</th>\n",
       "      <td>0.2086956569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 07:00:00</th>\n",
       "      <td>0.2088888940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 22:00:00</th>\n",
       "      <td>0.2104166717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       C6H6_ug_m3\n",
       "Data                             \n",
       "2021-05-19 03:00:00  0.1500000022\n",
       "2021-05-18 01:00:00  0.1500000022\n",
       "2021-05-19 02:00:00  0.1525000023\n",
       "2021-05-19 01:00:00  0.1666666692\n",
       "2021-06-01 05:00:00  0.1666666692\n",
       "2021-07-26 03:00:00  0.1666666702\n",
       "2021-05-18 02:00:00  0.1675000029\n",
       "2021-05-19 04:00:00  0.1729166697\n",
       "2021-05-18 00:00:00  0.1729166699\n",
       "2021-06-01 02:00:00  0.1729729756\n",
       "2021-06-01 03:00:00  0.1739130461\n",
       "2021-06-01 04:00:00  0.1739130461\n",
       "2021-06-01 01:00:00  0.1750000026\n",
       "2021-04-25 01:00:00  0.1750000026\n",
       "2021-05-19 00:00:00  0.1750000031\n",
       "2021-07-26 04:00:00  0.1750000045\n",
       "2021-04-25 05:00:00  0.1800000027\n",
       "2021-04-25 04:00:00  0.1804347855\n",
       "2021-04-25 02:00:00  0.1853658568\n",
       "2021-04-25 06:00:00  0.1866666699\n",
       "2021-04-25 03:00:00  0.1869565252\n",
       "2021-06-01 06:00:00  0.1911111154\n",
       "2021-04-15 08:00:00  0.1916666708\n",
       "2021-05-18 03:00:00  0.1916666708\n",
       "2021-11-19 02:00:00  0.1970588289\n",
       "2021-05-22 05:00:00  0.1979166702\n",
       "2021-06-01 00:00:00  0.1979166710\n",
       "2021-05-20 22:00:00  0.2000000042\n",
       "2021-11-19 04:00:00  0.2000000054\n",
       "2021-11-18 18:00:00  0.2000000055\n",
       "2021-11-18 20:00:00  0.2000000055\n",
       "2021-11-18 19:00:00  0.2000000055\n",
       "2021-11-19 07:00:00  0.2000000055\n",
       "2021-07-01 23:00:00  0.2000000061\n",
       "2021-04-25 00:00:00  0.2020833377\n",
       "2021-11-18 22:00:00  0.2028571484\n",
       "2021-11-19 05:00:00  0.2028571484\n",
       "2021-11-19 06:00:00  0.2028571484\n",
       "2021-06-02 02:00:00  0.2051282101\n",
       "2021-11-18 21:00:00  0.2055555615\n",
       "2021-11-18 23:00:00  0.2058823586\n",
       "2021-11-19 09:00:00  0.2058823586\n",
       "2021-11-19 08:00:00  0.2058823586\n",
       "2021-07-15 00:00:00  0.2062500059\n",
       "2021-04-15 09:00:00  0.2063829837\n",
       "2021-05-20 21:00:00  0.2083333383\n",
       "2021-05-31 23:00:00  0.2083333383\n",
       "2021-04-17 07:00:00  0.2086956569\n",
       "2021-06-01 07:00:00  0.2088888940\n",
       "2021-06-01 22:00:00  0.2104166717"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stampa le 50 ore con i livelli di benzene più bassi\n",
    "df_C6H6Min = df_C6H6avg.sort_values('C6H6_ug_m3', ascending = True).head(50)\n",
    "df_C6H6Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_K-JKaLUz5nt"
   },
   "outputs": [],
   "source": [
    "# Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "_ijWhBlMz5nt"
   },
   "outputs": [],
   "source": [
    "#Elimina i valori nulli e calcola la media oraria sul dataframe creato per il sensore H2S\n",
    "df_H2S, df_H2Savg = media_oraria(df_DatiPuliti, 'H2S_ug_m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true,
    "id": "2P9kMGkGz5nu",
    "outputId": "d6a186ca-fa6c-4a82-9331-de146d23b0e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H2S_ug_m3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-11 18:00:00</th>\n",
       "      <td>71.2354162931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-11 19:00:00</th>\n",
       "      <td>67.1854169269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-31 19:00:00</th>\n",
       "      <td>64.0794120045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-31 20:00:00</th>\n",
       "      <td>56.0463415762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29 18:00:00</th>\n",
       "      <td>55.7520837237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-01 20:00:00</th>\n",
       "      <td>55.6000002817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09 17:00:00</th>\n",
       "      <td>53.9312498470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-11 20:00:00</th>\n",
       "      <td>52.8000000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-31 18:00:00</th>\n",
       "      <td>51.2294121069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-28 20:00:00</th>\n",
       "      <td>50.6483872860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-10 19:00:00</th>\n",
       "      <td>50.5500005086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 20:00:00</th>\n",
       "      <td>49.8416671852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-10 18:00:00</th>\n",
       "      <td>48.1777780718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-01 19:00:00</th>\n",
       "      <td>48.0674998045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-23 18:00:00</th>\n",
       "      <td>47.9458335241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-23 19:00:00</th>\n",
       "      <td>47.4562499523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-29 17:00:00</th>\n",
       "      <td>47.3458333015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-30 20:00:00</th>\n",
       "      <td>46.7062497735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13 20:00:00</th>\n",
       "      <td>46.5750002215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-27 18:00:00</th>\n",
       "      <td>44.9520834386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-01 21:00:00</th>\n",
       "      <td>44.9340908527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01 21:00:00</th>\n",
       "      <td>44.6041663438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-10 20:00:00</th>\n",
       "      <td>44.5916668574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29 19:00:00</th>\n",
       "      <td>44.0395832260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-26 19:00:00</th>\n",
       "      <td>43.8145836194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-10 18:00:00</th>\n",
       "      <td>43.7583331615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-28 21:00:00</th>\n",
       "      <td>43.1586208179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-11 21:00:00</th>\n",
       "      <td>43.0020836393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13 21:00:00</th>\n",
       "      <td>42.9937499364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09 16:00:00</th>\n",
       "      <td>42.2979165961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-26 20:00:00</th>\n",
       "      <td>41.9812503358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-28 19:00:00</th>\n",
       "      <td>41.9613639116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-26 18:00:00</th>\n",
       "      <td>41.7229164342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-13 17:00:00</th>\n",
       "      <td>41.6708333443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-09 19:00:00</th>\n",
       "      <td>41.5875001699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-04 20:00:00</th>\n",
       "      <td>41.5083333304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-12 14:00:00</th>\n",
       "      <td>41.1083330711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-12 19:00:00</th>\n",
       "      <td>40.7687502354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 18:00:00</th>\n",
       "      <td>40.4770833651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 19:00:00</th>\n",
       "      <td>40.3312499772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-27 17:00:00</th>\n",
       "      <td>40.3062500705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-30 19:00:00</th>\n",
       "      <td>40.2833332717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-24 16:00:00</th>\n",
       "      <td>40.2645836125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-10 19:00:00</th>\n",
       "      <td>40.0624999603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-28 18:00:00</th>\n",
       "      <td>39.4033339183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 17:00:00</th>\n",
       "      <td>39.2166668177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-12 18:00:00</th>\n",
       "      <td>39.0708335290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09 20:00:00</th>\n",
       "      <td>38.9063829107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23 17:00:00</th>\n",
       "      <td>38.7125000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-23 17:00:00</th>\n",
       "      <td>38.5583333770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         H2S_ug_m3\n",
       "Data                              \n",
       "2021-08-11 18:00:00  71.2354162931\n",
       "2021-08-11 19:00:00  67.1854169269\n",
       "2021-07-31 19:00:00  64.0794120045\n",
       "2021-07-31 20:00:00  56.0463415762\n",
       "2021-06-29 18:00:00  55.7520837237\n",
       "2021-08-01 20:00:00  55.6000002817\n",
       "2021-07-09 17:00:00  53.9312498470\n",
       "2021-08-11 20:00:00  52.8000000368\n",
       "2021-07-31 18:00:00  51.2294121069\n",
       "2021-07-28 20:00:00  50.6483872860\n",
       "2021-07-10 19:00:00  50.5500005086\n",
       "2021-07-01 20:00:00  49.8416671852\n",
       "2021-07-10 18:00:00  48.1777780718\n",
       "2021-08-01 19:00:00  48.0674998045\n",
       "2021-05-23 18:00:00  47.9458335241\n",
       "2021-05-23 19:00:00  47.4562499523\n",
       "2021-05-29 17:00:00  47.3458333015\n",
       "2021-07-30 20:00:00  46.7062497735\n",
       "2021-08-13 20:00:00  46.5750002215\n",
       "2021-07-27 18:00:00  44.9520834386\n",
       "2021-08-01 21:00:00  44.9340908527\n",
       "2021-07-01 21:00:00  44.6041663438\n",
       "2021-07-10 20:00:00  44.5916668574\n",
       "2021-06-29 19:00:00  44.0395832260\n",
       "2021-07-26 19:00:00  43.8145836194\n",
       "2021-08-10 18:00:00  43.7583331615\n",
       "2021-07-28 21:00:00  43.1586208179\n",
       "2021-08-11 21:00:00  43.0020836393\n",
       "2021-08-13 21:00:00  42.9937499364\n",
       "2021-07-09 16:00:00  42.2979165961\n",
       "2021-07-26 20:00:00  41.9812503358\n",
       "2021-07-28 19:00:00  41.9613639116\n",
       "2021-07-26 18:00:00  41.7229164342\n",
       "2021-07-13 17:00:00  41.6708333443\n",
       "2021-08-09 19:00:00  41.5875001699\n",
       "2021-07-04 20:00:00  41.5083333304\n",
       "2021-04-12 14:00:00  41.1083330711\n",
       "2021-08-12 19:00:00  40.7687502354\n",
       "2021-06-23 18:00:00  40.4770833651\n",
       "2021-06-23 19:00:00  40.3312499772\n",
       "2021-07-27 17:00:00  40.3062500705\n",
       "2021-07-30 19:00:00  40.2833332717\n",
       "2021-06-24 16:00:00  40.2645836125\n",
       "2021-08-10 19:00:00  40.0624999603\n",
       "2021-07-28 18:00:00  39.4033339183\n",
       "2021-07-12 17:00:00  39.2166668177\n",
       "2021-07-12 18:00:00  39.0708335290\n",
       "2021-07-09 20:00:00  38.9063829107\n",
       "2021-06-23 17:00:00  38.7125000904\n",
       "2021-05-23 17:00:00  38.5583333770"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stampa le 50 ore con i livelli di acido solfidrico del sensore H2S più alti\n",
    "df_H2SMax= df_H2Savg.sort_values('H2S_ug_m3', ascending = False).head(50)\n",
    "df_H2SMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vif-8rM_z5nu",
    "outputId": "76f5ed23-910c-4f7b-f3cd-a6153aa37480"
   },
   "outputs": [],
   "source": [
    "# Stampa le 50 ore con i livelli di acido solfidrico del sensore H2S più basso\n",
    "df_H2SMin= df_H2Savg.sort_values('H2S_ug_m3', ascending = True).head(50)\n",
    "df_H2SMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimina i valori nulli e calcola la media oraria sul dataframe creato per il sensore H2SJ\n",
    "df_H2SJ, df_H2SJavg = media_oraria(df_DatiPuliti, 'H2SJ_ug_m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAQXorXOz5nv",
    "outputId": "730016d1-5367-4305-e72b-003e23572482"
   },
   "outputs": [],
   "source": [
    "# Stampa le 50 ore con i livelli di acido solfidrico del sensore H2SJ più alti\n",
    "df_H2SJMax= df_H2SJavg.sort_values('H2SJ_ug_m3', ascending = False).head(50)\n",
    "df_H2SJMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFfCxcBSz5nw",
    "outputId": "2e3d8e86-eaea-4db4-a871-02df83507686"
   },
   "outputs": [],
   "source": [
    "# Stampa le 50 ore con i livelli di acido solfidrico del sensore H2SJ più bassi\n",
    "df_H2SJMin= df_H2SJavg.sort_values('H2SJ_ug_m3', ascending = True).head(50)\n",
    "df_H2SJMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juoqhY7-z5nw"
   },
   "outputs": [],
   "source": [
    "# Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1655304361634,
     "user": {
      "displayName": "Carmine Martinelli",
      "userId": "17979448709595778797"
     },
     "user_tz": -120
    },
    "id": "jWf6C1cSz5nw"
   },
   "outputs": [],
   "source": [
    "#Elimina i valori nulli e calcola la media oraria sul dataframe creato per il sensore VOC\n",
    "df_VOC, df_VOCavg = media_oraria(df_DatiPuliti, 'VOC_ppm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8ucBSp1z5nx"
   },
   "outputs": [],
   "source": [
    "# Stampa le 50 ore con i livelli di VOC del sensore VOC più alti\n",
    "df_VOCMax= df_VOCavg.sort_values('VOC_ppm', ascending = False).head(50)\n",
    "df_VOCMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSlxPad6z5ny",
    "outputId": "9dcd347b-55dc-4c9b-966c-44f9ee0bca99"
   },
   "outputs": [],
   "source": [
    "# Stampa le 50 ore con i livelli di VOC del sensore VOC più bassi\n",
    "df_VOCMin= df_VOCavg.sort_values('VOC_ppm', ascending = True).head(50)\n",
    "df_VOCMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimina i valori nulli e calcola la media oraria sul dataframe creato per il sensore PIDVOC\n",
    "df_PIDVOC, df_PIDVOCavg = media_oraria(df_DatiPuliti, 'PIDVOC_ppb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ap47eeIJz5ny",
    "outputId": "8e6c2df2-f6a8-45d1-8c11-936bebcad5df"
   },
   "outputs": [],
   "source": [
    "# Stampa le 50 ore con i livelli di VOC del sensore PIDVOC più alti\n",
    "df_PIDVOCMax= df_PIDVOCavg.sort_values('PIDVOC_ppb', ascending = False).head(50)\n",
    "df_PIDVOCMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmmjSGmoz5ny"
   },
   "outputs": [],
   "source": [
    "# Stampa le 50 ore con i livelli di VOC del sensore PIDVOC più bassi\n",
    "df_PIDVOCMin= df_PIDVOCavg.sort_values('PIDVOC_ppb', ascending = True).head(50)\n",
    "df_PIDVOCMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQbwEz_xz5nz"
   },
   "outputs": [],
   "source": [
    "# Query 7 & 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\Antonio\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Giorno</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-06</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2021-12-04</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2021-12-05</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2021-12-08</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Giorno  count\n",
       "0   2021-01-06     38\n",
       "1   2021-01-07     42\n",
       "2   2021-01-08    235\n",
       "3   2021-01-11      6\n",
       "4   2021-02-06     42\n",
       "..         ...    ...\n",
       "127 2021-12-04     48\n",
       "128 2021-12-05    457\n",
       "129 2021-12-07    475\n",
       "130 2021-12-08     79\n",
       "131 2021-12-11     11\n",
       "\n",
       "[132 rows x 2 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Giornate con fallimenti ND (i fallimenti nell'invio dei dati sono uguali per ogni sensore)\n",
    "df_Fail_ND = df_DatiSensori[['Data','TRS_ppb','VOC_ppm','C6H6_ug_m3','H2S_ug_m3','H2SJ_ug_m3','PIDVOC_ppb']].copy()\n",
    "df_Fail_ND['Giorno'] = pd.to_datetime(df_Fail_ND['Data'].dt.strftime('%d/%m/%Y'))\n",
    "df_Fail_ND = df_Fail_ND.TRS_ppb.isnull().groupby(df_Fail_ND['Giorno']).sum().transform(int).reset_index(name='count')\n",
    "df_Fail_ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Giorno</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2021-08-14</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Giorno  count\n",
       "108 2021-11-07   1152\n",
       "85  2021-08-14   1025\n",
       "79  2021-07-29    514"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 giorni con il maggior numero di fallimenti\n",
    "df_Fail_ND.sort_values('count', ascending = False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Giorno</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2021-10-24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Giorno  count\n",
       "95  2021-10-20      4\n",
       "99  2021-10-24      4\n",
       "106 2021-10-31      4"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 giorni con il minor numero di fallimenti\n",
    "df_Fail_ND.sort_values('count', ascending = True).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 9, 10 e 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea due liste con tutti gli inquinanti e i relativi stati\n",
    "inquinanti = ['TRS_ppb','VOC_ppm','C6H6_ug_m3','H2S_ug_m3','H2SJ_ug_m3','PIDVOC_ppb']\n",
    "stato_Inquinanti = ['TRS_stato','VOC_stato','C6H6_stato', 'H2S_stato','H2SJ_stato', 'PIDVOC_stato']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensori</th>\n",
       "      <th>Fallimenti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRS_ppb</td>\n",
       "      <td>13460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VOC_ppm</td>\n",
       "      <td>13613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C6H6_ug_m3</td>\n",
       "      <td>13001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H2S_ug_m3</td>\n",
       "      <td>13091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H2SJ_ug_m3</td>\n",
       "      <td>13426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PIDVOC_ppb</td>\n",
       "      <td>13051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sensori  Fallimenti\n",
       "0     TRS_ppb       13460\n",
       "1     VOC_ppm       13613\n",
       "2  C6H6_ug_m3       13001\n",
       "3   H2S_ug_m3       13091\n",
       "4  H2SJ_ug_m3       13426\n",
       "5  PIDVOC_ppb       13051"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crea un dataframe che contiene la somma dei fallimenti \n",
    "# oltre alle righe con 'ND' che indicano il fallimento nel trasmettere i dati, consideriamo fallimento\n",
    "# anche la presenza consecutiva massiccia di valori 0\n",
    "fails = []\n",
    "df_NFails = pd.DataFrame({'Fallimenti':np.arange(6)})\n",
    "df_NFails = pd.DataFrame({'Sensori':np.arange(6)})\n",
    "for column in range(len(inquinanti)):\n",
    "    df_Fail = df_Dati[[inquinanti[column], stato_Inquinanti[column]]].copy()\n",
    "    errors = df_Fail[inquinanti[column]].ne(df_Fail\n",
    "                                  [inquinanti[column]].shift()).cumsum()[df_Fail\n",
    "                                                                         [inquinanti[column]].eq(0.0)].value_counts().ge(24).sum()\n",
    "    num_ND= df_Fail[stato_Inquinanti[column]].value_counts()[\"ND\"]\n",
    "    fails.append(num_ND + errors)\n",
    "\n",
    "df_NFails['Sensori'] = inquinanti\n",
    "df_NFails['Fallimenti'] = fails\n",
    "df_NFails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensori</th>\n",
       "      <th>Fallimenti</th>\n",
       "      <th>Dati TOT</th>\n",
       "      <th>Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRS_ppb</td>\n",
       "      <td>13460</td>\n",
       "      <td>152376.0</td>\n",
       "      <td>0.0883341209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VOC_ppm</td>\n",
       "      <td>13613</td>\n",
       "      <td>66074.0</td>\n",
       "      <td>0.2060265763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C6H6_ug_m3</td>\n",
       "      <td>13001</td>\n",
       "      <td>153216.0</td>\n",
       "      <td>0.0848540622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H2S_ug_m3</td>\n",
       "      <td>13091</td>\n",
       "      <td>149554.0</td>\n",
       "      <td>0.0875335999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H2SJ_ug_m3</td>\n",
       "      <td>13426</td>\n",
       "      <td>139590.0</td>\n",
       "      <td>0.0961816749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PIDVOC_ppb</td>\n",
       "      <td>13051</td>\n",
       "      <td>150890.0</td>\n",
       "      <td>0.0864934721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sensori  Fallimenti  Dati TOT         Media\n",
       "0     TRS_ppb       13460  152376.0  0.0883341209\n",
       "1     VOC_ppm       13613   66074.0  0.2060265763\n",
       "2  C6H6_ug_m3       13001  153216.0  0.0848540622\n",
       "3   H2S_ug_m3       13091  149554.0  0.0875335999\n",
       "4  H2SJ_ug_m3       13426  139590.0  0.0961816749\n",
       "5  PIDVOC_ppb       13051  150890.0  0.0864934721"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NFails.at[0, 'Dati TOT'] = len(dfTRS)\n",
    "df_NFails.at[1, 'Dati TOT'] = len(dfVOC)\n",
    "df_NFails.at[2, 'Dati TOT'] = len(dfC6H6)\n",
    "df_NFails.at[3, 'Dati TOT'] = len(dfH2S)\n",
    "df_NFails.at[4, 'Dati TOT'] = len(dfH2SJ)\n",
    "df_NFails.at[5, 'Dati TOT'] = len(dfPIDVOC)\n",
    "df_NFails['Media'] = df_NFails['Fallimenti'].div(df_NFails['Dati TOT'])\n",
    "df_NFails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13613"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prende il massimo dal dataframe\n",
    "df_NFails['Fallimenti'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13001"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prende il minimo dal dataframe\n",
    "df_NFails['Fallimenti'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALISI VISUALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione di un dataset per la media oraria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MediaOraria = pd.concat([df_C6H6avg ,df_H2Savg['H2S_ug_m3'], df_H2SJavg['H2SJ_ug_m3'], df_VOCavg['VOC_ppm'], df_PIDVOCavg['PIDVOC_ppb']], axis=1)\n",
    "# df_MediaOraria\n",
    "df_MediaOraria.to_excel('media_oraria.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CORRELAZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione correlazione\n",
    "def corr_Sensori(df, colonna1, colonna2, postazione = None):\n",
    "    if postazione != None:\n",
    "        df1 = df[df['postazione'] == postazione]\n",
    "    else:\n",
    "        df1 = df.copy()\n",
    "    df1.plot.scatter(x= colonna1, y=colonna2)\n",
    "    a,b = np.polyfit(df1[colonna1].to_list(), df1[colonna2].to_list(), 1) #Inferiamo y =ax + b\n",
    "    x1 = min(df1[colonna1].to_list())\n",
    "    x2 = max(df1[colonna1].to_list())\n",
    "    plt.plot([x1,x2], [a*x1 +b, a*x2 +b], color = 'red')\n",
    "    plt.show()\n",
    "    cc = np.corrcoef(df1[colonna1], df1[colonna2])[1,0]\n",
    "    cs = df1[[colonna1, colonna2]].corr(method = 'spearman')\n",
    "    return cc, cs.iloc[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELAZIONE 1 TRA I SENSORI H2S E H2SJ NELLE VARIE POSTAZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un dataframe contenente entrambi i sensori, rinomina le colonne ed elimina i valori nulli\n",
    "df_AcidoSolf = df_DatiPuliti[['postazione', 'Data', 'H2S_ug_m3', 'H2SJ_ug_m3']]\n",
    "df_AcidoSolf = df_AcidoSolf.dropna()\n",
    "df_AcidoSolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM05_01479\n",
    "pearson, spearman= corr_Sensori(df_AcidoSolf, 'H2S_ug_m3', 'H2SJ_ug_m3','ATM05_01479')\n",
    "print('Coefficiente di correlazione tra H2S e H2SJ con pearson per la postazione ATM05_01479 è ', pearson)\n",
    "print('Coefficiente di correlazione tra H2S e H2SJ con spearman per la postazione ATM05_01479 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM07_01480\n",
    "pearson, spearman = corr_Sensori(df_AcidoSolf, 'H2S_ug_m3', 'H2SJ_ug_m3', 'ATM07_01480')\n",
    "print('Coefficiente di correlazione tra H2S e H2SJ con pearson per la postazione ATM07_01480 è ', pearson)\n",
    "print('Coefficiente di correlazione tra H2S e H2SJ con spearman per la postazione ATM07_01480 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM10_01481\n",
    "pearson, spearman = corr_Sensori(df_AcidoSolf, 'H2S_ug_m3', 'H2SJ_ug_m3', 'ATM10_01481' )\n",
    "print('Coefficiente di correlazione tra H2S e H2SJ con pearson per la postazione ATM10_01481 è ', pearson)\n",
    "print('Coefficiente di correlazione tra H2S e H2SJ con spearman per la postazione ATM10_01481 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM14_01486\n",
    "pearson, spearman= corr_Sensori(df_AcidoSolf, 'H2S_ug_m3', 'H2SJ_ug_m3', 'ATM14_01486' )\n",
    "print('Coefficiente di correlazione tra H2S e H2SJ con pearson per la postazione ATM14_01486 è ', pearson)\n",
    "print('Coefficiente di correlazione tra H2S e H2SJ con spearman per la postazione ATM14_01486 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELAZIONE 2 TRA I SENSORI VOC E PIDVOC NELLE VARIE POSTAZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un dataframe contenente entrambi i sensori, rinomina le colonne ed elimina i valori nulli\n",
    "df_SensoriVOC = df_DatiPuliti[['postazione', 'Data', 'VOC_ppm', 'PIDVOC_ppb']]\n",
    "df_SensoriVOC = df_SensoriVOC.dropna()\n",
    "df_SensoriVOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM05_01479\n",
    "pearson, spearman= corr_Sensori(df_SensoriVOC, 'VOC_ppm', 'PIDVOC_ppb', 'ATM05_01479' )\n",
    "print('Coefficiente di correlazione tra VOC e PIDVOC con pearson per la postazione ATM05_01479 è ', pearson)\n",
    "print('Coefficiente di correlazione tra VOC e PIDVOC con spearman per la postazione ATM05_01479 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM07_01480\n",
    "pearson, spearman = corr_Sensori(df_SensoriVOC, 'VOC_ppm', 'PIDVOC_ppb', 'ATM07_01480' )\n",
    "print('Coefficiente di correlazione tra VOC e PIDVOC con pearson per la postazione ATM07_01480 è ', pearson)\n",
    "print('Coefficiente di correlazione tra VOC e PIDVOC con spearman per la postazione ATM07_01480 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM10_01481\n",
    "pearson, spearman = corr_Sensori(df_SensoriVOC, 'VOC_ppm', 'PIDVOC_ppb' , 'ATM10_01481')\n",
    "print('Coefficiente di correlazione tra VOC e PIDVOC con pearson per la postazione ATM10_01481 è ', pearson)\n",
    "print('Coefficiente di correlazione tra VOC e PIDVOC con spearman per la postazione ATM10_01481 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM14_01486\n",
    "pearson, spearman= corr_Sensori(df_SensoriVOC, 'VOC_ppm', 'PIDVOC_ppb', 'ATM14_01486' )\n",
    "print('Coefficiente di correlazione tra VOC e PIDVOC con pearson per la postazione ATM14_01486 è ', pearson)\n",
    "print('Coefficiente di correlazione tra VOC e PIDVOC con spearman per la postazione ATM14_01486 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELAZIONE 3 TRA I SENSORI TRS E H2S NELLE VARIE POSTAZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SenTRS_H2S = df_DatiPuliti[['postazione', 'Data', 'TRS_ppb', 'H2S_ug_m3']]\n",
    "df_SenTRS_H2S = df_SenTRS_H2S.dropna()\n",
    "df_SenTRS_H2S.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM05_01479\n",
    "pearson, spearman = corr_Sensori(df_SenTRS_H2S, 'TRS_ppb', 'H2S_ug_m3', 'ATM05_01479' )\n",
    "print('Coefficiente di correlazione tra TRS e H2S con pearson per la postazione ATM05_01479 è ', pearson)\n",
    "print('Coefficiente di correlazione tra TRS e H2S con spearman per la postazione ATM05_01479 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM07_01480\n",
    "pearson, spearman= corr_Sensori(df_SenTRS_H2S, 'TRS_ppb', 'H2S_ug_m3', 'ATM07_01480' )\n",
    "print('Coefficiente di correlazione tra TRS e H2S con pearson per la postazione ATM07_01480 è ', pearson)\n",
    "print('Coefficiente di correlazione tra TRS e H2S con spearman per la postazione ATM07_01480 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM10_01481\n",
    "pearson, spearman= corr_Sensori(df_SenTRS_H2S, 'TRS_ppb', 'H2S_ug_m3', 'ATM10_01481' )\n",
    "print('Coefficiente di correlazione tra TRS e H2S con pearson per la postazione ATM10_01481 è ', pearson)\n",
    "print('Coefficiente di correlazione tra TRS e H2S con spearman per la postazione ATM10_01481 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM14_01486\n",
    "pearson, spearman= corr_Sensori(df_SenTRS_H2S, 'TRS_ppb', 'H2S_ug_m3', 'ATM14_01486' )\n",
    "print('Coefficiente di correlazione tra TRS e H2S con pearson per la postazione ATM14_01486 è ', pearson)\n",
    "print('Coefficiente di correlazione tra TRS e H2S con spearman per la postazione ATM14_01486 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELAZIONE 4 TRA I SENSORI TRS E H2SJ NELLE VARIE POSTAZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SenTRS_H2SJ = df_DatiPuliti[['postazione', 'Data', 'TRS_ppb', 'H2SJ_ug_m3']]\n",
    "df_SenTRS_H2SJ = df_SenTRS_H2SJ.dropna()\n",
    "df_SenTRS_H2SJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM05_01479\n",
    "pearson, spearman= corr_Sensori(df_SenTRS_H2SJ, 'TRS_ppb', 'H2SJ_ug_m3' , 'ATM05_01479')\n",
    "print('Coefficiente di correlazione tra TRS e H2SJ con pearson per la postazione ATM05_01479 è ', pearson)\n",
    "print('Coefficiente di correlazione tra TRS e H2SJ con spearman per la postazione ATM05_01479 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM07_01480\n",
    "pearson, spearman= corr_Sensori(df_SenTRS_H2SJ, 'TRS_ppb', 'H2SJ_ug_m3', 'ATM07_01480' )\n",
    "print('Coefficiente di correlazione tra TRS e H2SJ con pearson per la postazione ATM07_01480 è ', pearson)\n",
    "print('Coefficiente di correlazione tra TRS e H2SJ con spearman per la postazione ATM07_01480 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM10_01481\n",
    "pearson, spearman= corr_Sensori(df_SenTRS_H2SJ, 'TRS_ppb', 'H2SJ_ug_m3' , 'ATM10_01481')\n",
    "print('Coefficiente di correlazione tra TRS e H2SJ con pearson per la postazione ATM10_01481 è ', pearson)\n",
    "print('Coefficiente di correlazione tra TRS e H2SJ con spearman per la postazione ATM10_01481 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM14_01486\n",
    "pearson, spearman= corr_Sensori(df_SenTRS_H2SJ, 'TRS_ppb', 'H2SJ_ug_m3' , 'ATM14_01486')\n",
    "print('Coefficiente di correlazione tra TRS e H2SJ con pearson per la postazione ATM14_01486 è ', pearson)\n",
    "print('Coefficiente di correlazione tra TRS e H2SJ con spearman per la postazione ATM14_01486 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELAZIONE 5 TRA I SENSORI VOC E C6H6 NELLE VARIE POSTAZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SenVOC_C6H6 = df_DatiPuliti[['postazione', 'Data', 'VOC_ppm', 'C6H6_ug_m3']]\n",
    "df_SenVOC_C6H6 = df_SenVOC_C6H6.dropna()\n",
    "df_SenVOC_C6H6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM05_01479\n",
    "pearson, spearman= corr_Sensori(df_SenVOC_C6H6, 'VOC_ppm', 'C6H6_ug_m3' , 'ATM05_01479')\n",
    "print('Coefficiente di correlazione tra VOC e C6H6 con pearson per la postazione ATM05_01479 è ', pearson)\n",
    "print('Coefficiente di correlazione tra VOC e C6H6 con spearman per la postazione ATM05_01479 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM07_01480\n",
    "pearson, spearman= corr_Sensori(df_SenVOC_C6H6, 'VOC_ppm', 'C6H6_ug_m3', 'ATM07_01480' )\n",
    "print('Coefficiente di correlazione tra VOC e C6H6 con pearson per la postazione ATM07_01480 è ', pearson)\n",
    "print('Coefficiente di correlazione tra VOC e C6H6 con spearman per la postazione ATM07_01480 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM10_01481\n",
    "pearson, spearman= corr_Sensori(df_SenVOC_C6H6, 'VOC_ppm', 'C6H6_ug_m3' , 'ATM10_01481')\n",
    "print('Coefficiente di correlazione tra VOC e C6H6 con pearson per la postazione ATM10_01481 è ', pearson)\n",
    "print('Coefficiente di correlazione tra VOC e C6H6 con spearman per la postazione ATM10_01481 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM14_01486\n",
    "pearson, spearman= corr_Sensori(df_SenVOC_C6H6, 'VOC_ppm', 'C6H6_ug_m3', 'ATM14_01486' )\n",
    "print('Coefficiente di correlazione tra VOC e C6H6 con pearson per la postazione ATM14_01486 è ', pearson)\n",
    "print('Coefficiente di correlazione tra VOC e C6H6 con spearman per la postazione ATM14_01486 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELAZIONE 6 TRA I SENSORI PIDVOC E C6H6 NELLE VARIE POSTAZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SenPIDVOC_C6H6 = df_DatiPuliti[['postazione', 'Data', 'PIDVOC_ppb', 'C6H6_ug_m3']]\n",
    "df_SenPIDVOC_C6H6 = df_SenPIDVOC_C6H6.dropna()\n",
    "df_SenPIDVOC_C6H6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM05_01479\n",
    "pearson, spearman= corr_Sensori(df_SenPIDVOC_C6H6, 'PIDVOC_ppb', 'C6H6_ug_m3', 'ATM05_01479' )\n",
    "print('Coefficiente di correlazione tra PIDVOC e C6H6 con pearson per la postazione ATM05_01479 è ', pearson)\n",
    "print('Coefficiente di correlazione tra PIDVOC e C6H6 con spearman per la postazione ATM05_01479 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM07_01480\n",
    "pearson, spearman= corr_Sensori(df_SenPIDVOC_C6H6, 'PIDVOC_ppb', 'C6H6_ug_m3' , 'ATM07_01480')\n",
    "print('Coefficiente di correlazione tra PIDVOC e C6H6 con pearson per la postazione ATM07_01480 è ', pearson)\n",
    "print('Coefficiente di correlazione tra PIDVOC e C6H6 con spearman per la postazione ATM07_01480 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM10_01481\n",
    "pearson, spearman= corr_Sensori(df_SenPIDVOC_C6H6, 'PIDVOC_ppb', 'C6H6_ug_m3', 'ATM10_01481' )\n",
    "print('Coefficiente di correlazione tra PIDVOC e C6H6 con pearson per la postazione ATM10_01481 è ', pearson)\n",
    "print('Coefficiente di correlazione tra PIDVOC e C6H6 con spearman per la postazione ATM10_01481 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per la stazione ATM14_01486\n",
    "pearson, spearman= corr_Sensori(df_SenPIDVOC_C6H6, 'PIDVOC_ppb', 'C6H6_ug_m3', 'ATM14_01486' )\n",
    "print('Coefficiente di correlazione tra PIDVOC e C6H6 con pearson per la postazione ATM14_01486 è ', pearson)\n",
    "print('Coefficiente di correlazione tra PIDVOC e C6H6 con spearman per la postazione ATM14_01486 è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELAZIONE 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSTAZIONI ATM05_01479 E ATM07_01480 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creazione_df(df, colonna1, colonna2, composto, df2 = None):\n",
    "    df_1 = df[df['postazione'] == colonna1].dropna()[composto].reset_index(drop = True).to_frame()\n",
    "    if df2 is None:\n",
    "        df_2 = df.copy()\n",
    "        df_2 = df_2[df_2['postazione'] == colonna2].dropna()[composto].reset_index(drop = True).to_frame()\n",
    "    else:\n",
    "        df_2 = df2.copy()\n",
    "        df_2 = df_2[colonna2].dropna().reset_index(drop = True).to_frame()\n",
    "    df_Full = pd.concat([df_1, df_2], axis=1)\n",
    "    df_Full.columns = [colonna1,colonna2]\n",
    "    df_Full = df_Full[[colonna1,colonna2]].fillna(0)\n",
    "    return df_Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore TRS_ppb\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM07_01480', 'TRS_ppb' ), 'ATM05_01479', 'ATM07_01480')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore C6H6_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM07_01480', 'C6H6_ug_m3' ), 'ATM05_01479', 'ATM07_01480')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore VOC_ppm\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM07_01480', 'VOC_ppm' ), 'ATM05_01479', 'ATM07_01480')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore PIDVOC_ppb\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM07_01480', 'PIDVOC_ppb' ), 'ATM05_01479', 'ATM07_01480')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2S_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM07_01480', 'H2S_ug_m3' ), 'ATM05_01479', 'ATM07_01480')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2SJ_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM07_01480', 'H2SJ_ug_m3' ), 'ATM05_01479', 'ATM07_01480')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSTAZIONI ATM05_01479 E ATM10_01481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore TRS_ppb\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM10_01481', 'TRS_ppb' ), 'ATM05_01479', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore C6H6_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM10_01481', 'C6H6_ug_m3' ), 'ATM05_01479', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore VOC_pp\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM10_01481', 'VOC_ppm' ), 'ATM05_01479', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore PIDVOC_ppm\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM10_01481', 'PIDVOC_ppb' ), 'ATM05_01479', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2S_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM10_01481', 'H2S_ug_m3' ), 'ATM05_01479', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2SJ_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM10_01481', 'H2SJ_ug_m3' ), 'ATM05_01479', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSTAZIONI ATM05_01479 E ATM14_01486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore TRS_ppb\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM14_01486', 'TRS_ppb' ), 'ATM05_01479', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore C6H6_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM14_01486', 'C6H6_ug_m3' ), 'ATM05_01479', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore VOC_ppm\n",
    "pearsonPost4, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM14_01486', 'VOC_ppm' ), 'ATM05_01479', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore PIDVOC_ppb\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM14_01486', 'PIDVOC_ppb' ), 'ATM05_01479', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2S_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM14_01486', 'H2S_ug_m3' ), 'ATM05_01479', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2SJ_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM05_01479', 'ATM14_01486', 'H2SJ_ug_m3' ), 'ATM05_01479', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSTAZIONI ATM07_01480 E ATM10_01481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore TRS_ppb\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM10_01481', 'TRS_ppb' ), 'ATM07_01480', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore C6H6_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM10_01481', 'C6H6_ug_m3' ), 'ATM07_01480', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore VOC_ppm\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM10_01481', 'VOC_ppm' ), 'ATM07_01480', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore PIDVOC_ppb\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM10_01481', 'PIDVOC_ppb' ), 'ATM07_01480', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2S_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM10_01481', 'H2S_ug_m3' ), 'ATM07_01480', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2SJ_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM10_01481', 'H2SJ_ug_m3' ), 'ATM07_01480', 'ATM10_01481')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSTAZIONI ATM07_01480 E ATM14_01486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore TRS_ppb\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM14_01486', 'TRS_ppb' ), 'ATM07_01480', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore C6H6_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM14_01486', 'C6H6_ug_m3' ), 'ATM07_01480', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore VOC_ppm\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM14_01486', 'VOC_ppm' ), 'ATM07_01480', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore PIDVOC_ppb\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM14_01486', 'PIDVOC_ppb' ), 'ATM07_01480', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2S_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM14_01486', 'H2S_ug_m3' ), 'ATM07_01480', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2SJ_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM07_01480', 'ATM14_01486', 'H2SJ_ug_m3' ), 'ATM07_01480', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSTAZIONI ATM10_01481 E ATM14_01486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore TRS_ppb\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM10_01481', 'ATM14_01486', 'TRS_ppb' ), 'ATM10_01481', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore C6H6_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM10_01481', 'ATM14_01486', 'C6H6_ug_m3' ), 'ATM10_01481', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore VOC_ppm\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM10_01481', 'ATM14_01486', 'VOC_ppm' ), 'ATM10_01481', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore PIDVOC_ppb\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM10_01481', 'ATM14_01486', 'PIDVOC_ppb' ), 'ATM10_01481', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2S_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM10_01481', 'ATM14_01486', 'H2S_ug_m3' ), 'ATM10_01481', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlazione per il sensore H2SJ_ug_m3\n",
    "pearson, spearman= corr_Sensori(creazione_df(df_Dati, 'ATM10_01481', 'ATM14_01486', 'H2SJ_ug_m3' ), 'ATM10_01481', 'ATM14_01486')\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELAZIONE 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DatiMeteo = pd.read_excel('Dati_Meteo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DatiMeteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stazione = ['ATM05_01479','ATM07_01480','ATM10_01481', 'ATM14_01486']\n",
    "sensore = ['TRS_ppb','C6H6_ug_m3', 'VOC_ppm', 'PIDVOC_ppb', 'H2S_ug_m3', 'H2SJ_ug_m3']\n",
    "meteo = ['temperatura_gradiC', 'direzione_vento_gradi','pressione_hPa', 'intensità_vento_km_h' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson, spearman = corr_Sensori(creazione_df(df_DatiPuliti, \n",
    "                                              stazione[2], meteo[3], sensore[5], df2 = df_DatiMeteo), stazione[2], meteo[3])\n",
    "print('Coefficiente di correlazione di pearson è ', pearson)\n",
    "print('Coefficiente di correlazione di spearman è ', spearman)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ElaborazioneDati.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
